{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sentence = 'Born in Philadelphia, he served in World War II and attended the University\\\n",
    "of Pennsylvania Law School. After graduating, he joined the law firm of Drinker Biddle & Reath\\\n",
    "and remained with them for his entire career. Sawyer worked as a corporate lawyer but is best\\\n",
    "known for his advocacy of civil liberties, especially in First Amendment cases.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Spacy dependency parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import spacy\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(Sentence)\n",
    "edges =[]\n",
    "for tok in doc:\n",
    "    for child in tok.children:\n",
    "        edges.append(('{0}-{1}'.format(tok.lower_,tok.i),\n",
    "                      '{0}-{1}'.format(child.lower_,child.i)))\n",
    "        \n",
    "graph = nx.Graph(edges)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# graph.edges\n",
    "# graph.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(nx.shortest_path_length(graph,source='born-0',target='universityof-13'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['born-0', 'served-5', 'attended-11', 'school-16', 'universityof-13']\n"
     ]
    }
   ],
   "source": [
    "print(nx.shortest_path(graph,source='born-0',target='universityof-13'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with StanfordCoreNLP dependency parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*!sudo pip install pycorenlp*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from pycorenlp import StanfordCoreNLP\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*After downloading StanfordCoreNLP must go inside the folder and run the following:*\n",
    "*java -mx4g -cp \"*\" edu.stanford.nlp.pipeline.StanfordCoreNLPServer -port 9000 -timeout 50000*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = StanfordCoreNLP('http://localhost:{0}'.format(9000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "document: Born in Philadelphia, he served in World War II and attended the Universityof Pennsylvania Law School. After graduating, he joined the law firm of Drinker Biddle & Reathand remained with them for his entire career. Sawyer worked as a corporate lawyer but is bestknown for his advocacy of civil liberties, especially in First Amendment cases.\n"
     ]
    }
   ],
   "source": [
    "def get_stanford_annotations(text, port=9000,\n",
    "                             annotators='tokenize,ssplit,pos,lemma,depparse,parse'):\n",
    "    output = nlp.annotate(text, properties={\n",
    "        \"timeout\": \"10000\",\n",
    "        \"ssplit.newlineIsSentenceBreak\": \"two\",\n",
    "        'annotators': annotators,\n",
    "        'outputFormat': 'json'\n",
    "    })\n",
    "    return output\n",
    "print('document: {0}'.format(Sentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = get_stanford_annotations(Sentence, port=9000,\n",
    "                                       annotators='tokenize,ssplit,pos,lemma,depparse')\n",
    "tokens = annotations['sentences'][0]['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  annotations['sentences'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path: [1, 6, 12, 17, 14]\n"
     ]
    }
   ],
   "source": [
    "# Load Stanford CoreNLP's dependency tree into a networkx graph\n",
    "edges = []\n",
    "dependencies = {}\n",
    "for edge in annotations['sentences'][0]['basicDependencies']:\n",
    "    edges.append((edge['governor'], edge['dependent']))\n",
    "    dependencies[(min(edge['governor'], edge['dependent']),\n",
    "                  max(edge['governor'], edge['dependent']))] = edge\n",
    "graph = nx.Graph(edges)\n",
    "#pprint(dependencies)\n",
    "#print('edges: {0}'.format(edges))\n",
    "\n",
    "# Find the shortest path\n",
    "token1 = 'Born'\n",
    "token2 = 'Universityof'\n",
    "for token in tokens:\n",
    "    \n",
    "    if token1 == token['originalText']:\n",
    "        token1_index = token['index']\n",
    "    if token2 == token['originalText']:\n",
    "        token2_index = token['index']\n",
    "path = nx.shortest_path(graph, source=token1_index, target=token2_index)\n",
    "print('path: {0}'.format(path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1\ttoken_text: Born\n",
      "Node 6\ttoken_text: served\n",
      "Node 12\ttoken_text: attended\n",
      "Node 17\ttoken_text: School\n",
      "Node 14\ttoken_text: Universityof\n"
     ]
    }
   ],
   "source": [
    "for token_id in path:\n",
    "    token = tokens[token_id-1]\n",
    "    token_text = token['originalText']\n",
    "    print('Node {0}\\ttoken_text: {1}'.format(token_id,token_text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
